{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f71909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def rfeFeature(indep_X, dep_Y, n):\n",
    "    rfelist = []\n",
    "\n",
    "    log_model = LogisticRegression(solver='lbfgs')\n",
    "    RF = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "    DT = DecisionTreeClassifier(criterion='gini', max_features='sqrt', splitter='best', random_state=0)\n",
    "    svc_model = SVC(kernel='linear', random_state=0)\n",
    "    rfemodellist = [log_model, svc_model, RF, DT]\n",
    "    \n",
    "    for model in rfemodellist:\n",
    "        print(model)\n",
    "        rfe = RFE(estimator=model, n_features_to_select=n)\n",
    "        rfe.fit(indep_X, dep_Y)\n",
    "        rfe_features = rfe.transform(indep_X)\n",
    "        rfelist.append(rfe_features)\n",
    "        \n",
    "    return rfelist\n",
    "\n",
    "def split_scalar(indep_X, dep_Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.25, random_state=0)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def cm_prediction(classifier, X_test, y_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return classifier, accuracy, report, X_test, y_test, cm\n",
    "\n",
    "def logistic(X_train, y_train, X_test, y_test):       \n",
    "    classifier = LogisticRegression(random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def svm_linear(X_train, y_train, X_test, y_test):\n",
    "    classifier = SVC(kernel='linear', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def svm_nl(X_train, y_train, X_test, y_test):\n",
    "    classifier = SVC(kernel='rbf', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def naive(X_train, y_train, X_test, y_test):       \n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def knn(X_train, y_train, X_test, y_test):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def decision(X_train, y_train, X_test, y_test):\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def random(X_train, y_train, X_test, y_test):\n",
    "    classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return cm_prediction(classifier, X_test, y_test)\n",
    "\n",
    "def rfe_classification(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf): \n",
    "    rfedataframe = pd.DataFrame(index=['Logistic', 'SVC', 'Random', 'DecisionTree'], \n",
    "                                columns=['Logistic', 'SVMl', 'SVMnl', 'KNN', 'Naive', 'Decision', 'Random'])\n",
    "\n",
    "    for number, idx in enumerate(rfedataframe.index):\n",
    "        rfedataframe['Logistic'][idx] = acclog[number]       \n",
    "        rfedataframe['SVMl'][idx] = accsvml[number]\n",
    "        rfedataframe['SVMnl'][idx] = accsvmnl[number]\n",
    "        rfedataframe['KNN'][idx] = accknn[number]\n",
    "        rfedataframe['Naive'][idx] = accnav[number]\n",
    "        rfedataframe['Decision'][idx] = accdes[number]\n",
    "        rfedataframe['Random'][idx] = accrf[number]\n",
    "    \n",
    "    return rfedataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c1f386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\AIML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\anaconda3\\envs\\AIML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\anaconda3\\envs\\AIML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\anaconda3\\envs\\AIML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\anaconda3\\envs\\AIML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\anaconda3\\envs\\AIML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\anaconda3\\envs\\AIML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\anaconda3\\envs\\AIML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\anaconda3\\envs\\AIML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\anaconda3\\envs\\AIML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\anaconda3\\envs\\AIML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(kernel='linear', random_state=0)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Selected Features by RFE for each model: [array([[ 3.        , 12.51815562,  1.        ,  0.        ,  0.        ,\n",
      "         0.        ],\n",
      "       [ 2.        , 10.7       ,  1.        ,  0.        ,  0.        ,\n",
      "         0.        ],\n",
      "       [ 1.        , 12.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ],\n",
      "       ...,\n",
      "       [ 3.        ,  9.1       ,  1.        ,  0.        ,  1.        ,\n",
      "         1.        ],\n",
      "       [ 0.        ,  8.5       ,  0.        ,  0.        ,  1.        ,\n",
      "         1.        ],\n",
      "       [ 0.        , 16.3       ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ]]), array([[3., 1., 0., 1., 0., 1.],\n",
      "       [2., 1., 0., 1., 0., 1.],\n",
      "       [1., 0., 0., 1., 0., 1.],\n",
      "       ...,\n",
      "       [3., 1., 0., 1., 1., 0.],\n",
      "       [0., 0., 0., 1., 1., 1.],\n",
      "       [0., 0., 0., 1., 0., 1.]]), array([[  3.        , 148.11267606,   3.07735602,  12.51815562,\n",
      "         38.86890244,   4.70559701],\n",
      "       [  2.        , 148.11267606,   0.7       ,  10.7       ,\n",
      "         34.        ,   4.70559701],\n",
      "       [  1.        ,  99.        ,   0.6       ,  12.        ,\n",
      "         34.        ,   4.70559701],\n",
      "       ...,\n",
      "       [  3.        , 110.        ,   6.        ,   9.1       ,\n",
      "         26.        ,   3.4       ],\n",
      "       [  0.        , 207.        ,   6.8       ,   8.5       ,\n",
      "         38.86890244,   4.70559701],\n",
      "       [  0.        , 100.        ,   1.        ,  16.3       ,\n",
      "         53.        ,   4.9       ]]), array([[ 3.07735602, 12.51815562, 38.86890244,  1.        ,  1.        ,\n",
      "         0.        ],\n",
      "       [ 0.7       , 10.7       , 34.        ,  1.        ,  1.        ,\n",
      "         0.        ],\n",
      "       [ 0.6       , 12.        , 34.        ,  0.        ,  1.        ,\n",
      "         0.        ],\n",
      "       ...,\n",
      "       [ 6.        ,  9.1       , 26.        ,  1.        ,  1.        ,\n",
      "         1.        ],\n",
      "       [ 6.8       ,  8.5       , 38.86890244,  0.        ,  1.        ,\n",
      "         1.        ],\n",
      "       [ 1.        , 16.3       , 53.        ,  0.        ,  1.        ,\n",
      "         0.        ]])]\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the data\n",
    "dataset1 = pd.read_csv(\"prep.csv\", index_col=None)\n",
    "df2 = pd.get_dummies(dataset1, drop_first=True)\n",
    "\n",
    "indep_X = df2.drop('classification_yes', axis=1)\n",
    "dep_Y = df2['classification_yes']\n",
    "\n",
    "# Perform RFE to select top 3 features\n",
    "rfelist = rfeFeature(indep_X, dep_Y, 6)\n",
    "print(\"Selected Features by RFE for each model:\", rfelist)\n",
    "\n",
    "# Initialize lists to store accuracy metrics\n",
    "acclog = []\n",
    "acclin = []\n",
    "accsvml = []\n",
    "accsvmnl = []\n",
    "accdes = []\n",
    "accrf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7a0c54",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "logistic() missing 1 required positional argument: 'y_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3caa4f45bc7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogistic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0macclog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: logistic() missing 1 required positional argument: 'y_test'"
     ]
    }
   ],
   "source": [
    "for i in rfelist:   \n",
    "    X_train, X_test, y_train, y_test=split_scalar(i,dep_Y)   \n",
    "    \n",
    "        \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=logistic(X_train,y_train,X_test)\n",
    "    acclog.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=svm_linear(X_train,y_train,X_test)  \n",
    "    accsvml.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=svm_NL(X_train,y_train,X_test)  \n",
    "    accsvmnl.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=knn(X_train,y_train,X_test)  \n",
    "    accknn.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Navie(X_train,y_train,X_test)  \n",
    "    accnav.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Decision(X_train,y_train,X_test)  \n",
    "    accdes.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=random(X_train,y_train,X_test)  \n",
    "    accrf.append(Accuracy)\n",
    "    \n",
    "result=rfe_classification(acclog,accsvml,accsvmnl,accknn,accnav,accdes,accrf)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9362a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2915fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e11f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9bd8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
